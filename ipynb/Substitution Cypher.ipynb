{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d472333-e5a1-4ef3-8d52-a09c4d873d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7626f2-c493-4383-895f-90d5b8a75665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0ea1ddf-611a-4412-8114-2ad0bfdfb337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s.attempt_to_pickle', 's.csv_exists', 's.data_csv_folder', 's.data_folder', 's.encoding_type', 's.load_csv', 's.load_dataframes', 's.load_object', 's.pickle_exists', 's.save_dataframes', 's.saves_csv_folder', 's.saves_folder', 's.saves_pickle_folder', 's.store_objects']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%run ../load_magic/storage.py\n",
    "s = Storage()\n",
    "[f's.{fn}' for fn in dir(s) if not fn.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6793df5-1374-4d6e-8756-159f0ef8060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['garbled_letters_counter_obj.clear', 'garbled_letters_counter_obj.copy', 'garbled_letters_counter_obj.elements', 'garbled_letters_counter_obj.fromkeys', 'garbled_letters_counter_obj.get', 'garbled_letters_counter_obj.items', 'garbled_letters_counter_obj.keys', 'garbled_letters_counter_obj.most_common', 'garbled_letters_counter_obj.pop', 'garbled_letters_counter_obj.popitem', 'garbled_letters_counter_obj.setdefault', 'garbled_letters_counter_obj.subtract', 'garbled_letters_counter_obj.update', 'garbled_letters_counter_obj.values']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'g': 10, 'r': 8, 'q': 7, 'v': 7, 'n': 7, 'b': 6, 'f': 4, 'h': 4, 'u': 4, 'z': 3, 'a': 3, 'y': 3, 'e': 3, 'c': 2, 'p': 2, 'j': 2, 'l': 1, 'V': 1, 'i': 1, 's': 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate the distribution of the letters in the garbled text\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "alphabet_regex = re.compile('[^A-Za-z]+')\n",
    "encoded_text = 'qrfcvgr zl vavgvny vzchyfr gung V fubhyq pbagenqvpg jubrire fnvq gung, \"qngr n qhqr\" jba bhg sbe zr'\n",
    "garbled_words_list = alphabet_regex.split(encoded_text)\n",
    "garbled_word_length_set = set([n for n in map(lambda x: len(x), garbled_words_list)])\n",
    "letter_regex = re.compile('[A-Za-z]')\n",
    "garbled_letters_list = letter_regex.findall(encoded_text)\n",
    "garbled_letters_counter_obj = Counter(garbled_letters_list)\n",
    "print([f'garbled_letters_counter_obj.{fn}' for fn in dir(garbled_letters_counter_obj) if not fn.startswith('_')])\n",
    "garbled_letters_counter_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "875ca0d9-7303-44b6-b1be-101407341922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Wordle\\saves\\pkl\\GLOVE_SMALL_DICT.pkl\n",
      "Pickling to C:\\Users\\daveb\\OneDrive\\Documents\\GitHub\\Wordle\\saves\\pkl\\GLOVE_SMALL_COUNTER.pkl\n",
      "1.4233295917510986 Wed Mar 30 07:11:08 2022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'t': 22.62368310155921, 'h': 14.742098609355246, 'e': 42.746734091866834, 'o': 28.435313948588284, 'f': 6.04677623261694, 'a': 49.959544879898864, 'n': 30.769490096923725, 'd': 15.132743362831858, 'i': 34.02697008006743, 'r': 31.0779603876949, 's': 29.11757269279393, 'w': 5.277286135693215, 'b': 11.003371260008429, 'y': 7.713442899283607, 'm': 15.335861778339654, 'v': 5.6131479140328695, 'u': 16.396544458491363, 'l': 23.79983143699958, 'p': 10.11504424778761, 'c': 15.321112515802781, 'g': 11.988621997471554, 'k': 10.138221660345554, 'j': 2.8158449220396125, 'x': 1.4517488411293722, 'q': 1.0, 'z': 3.723135271807838}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Store a list of valid words (in a dictionary) and a \"normal\" letter distibution for your language (in a list)\n",
    "import time\n",
    "\n",
    "GLOVE_840B_300D_PATH = '../data/300d/glove.840B.300d.txt'\n",
    "GLOVE_6B_50D_PATH = '../data/50d/glove.6B.50d.txt'\n",
    "t0 = time.time()\n",
    "if s.pickle_exists('GLOVE_SMALL_DICT'):\n",
    "    glove_dict = s.load_object('GLOVE_SMALL_DICT')\n",
    "    counter_obj = s.load_object('GLOVE_SMALL_COUNTER')\n",
    "else:\n",
    "    glove_dict = {}\n",
    "    letters_list = []\n",
    "    with open(GLOVE_6B_50D_PATH, 'r', encoding='utf8') as infile:\n",
    "        for line in infile:\n",
    "            parts_list = line.split()\n",
    "            word_str = parts_list[0]\n",
    "            if not alphabet_regex.search(word_str):\n",
    "                letter_count = len(word_str)\n",
    "                if letter_count in garbled_word_length_set:\n",
    "                    words_list = glove_dict.get(letter_count, [])\n",
    "                    words_list.append(word_str)\n",
    "                    glove_dict[letter_count] = words_list\n",
    "                    for letter in word_str:\n",
    "                        letters_list.append(letter)\n",
    "    counter_obj = Counter(letters_list)\n",
    "    s.store_objects(GLOVE_SMALL_DICT=glove_dict, GLOVE_SMALL_COUNTER=counter_obj)\n",
    "t1 = time.time()\n",
    "print(t1-t0, time.ctime(t1))\n",
    "count_min = min(counter_obj.values())\n",
    "letter_freq_dict = {k: v/count_min for k, v in counter_obj.items()}\n",
    "letter_freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa6f9bdf-c0f2-42be-a4d9-e77595862adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 49.959544879898864), ('e', 42.746734091866834), ('i', 34.02697008006743), ('r', 31.0779603876949), ('n', 30.769490096923725), ('s', 29.11757269279393), ('o', 28.435313948588284), ('l', 23.79983143699958), ('t', 22.62368310155921), ('u', 16.396544458491363), ('m', 15.335861778339654), ('c', 15.321112515802781), ('d', 15.132743362831858), ('h', 14.742098609355246), ('g', 11.988621997471554), ('b', 11.003371260008429), ('k', 10.138221660345554), ('p', 10.11504424778761), ('y', 7.713442899283607), ('f', 6.04677623261694), ('v', 5.6131479140328695), ('w', 5.277286135693215), ('z', 3.723135271807838), ('j', 2.8158449220396125), ('x', 1.4517488411293722), ('q', 1.0)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Repeat: Set an array (rank) from all 26 letters to float (rank('A')=rank('B')=...=rank('Z')=0.0)\n",
    "count_min = min(counter_obj.values())\n",
    "lower_letter_freq_dict = {k: v/count_min for k, v in counter_obj.items() if k.lower() == k}\n",
    "count_min = min(lower_letter_freq_dict.values())\n",
    "lower_letter_freq_dict = {k: v/count_min for k, v in lower_letter_freq_dict.items()}\n",
    "letter_ranked_tuples_list = sorted([(k, v) for k, v in lower_letter_freq_dict.items()], key=lambda x:x[1], reverse=True)\n",
    "letter_ranked_tuples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc28e3aa-4413-4680-a2ad-d508b799516b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('g', 10.0), ('r', 8.0), ('q', 7.0), ('v', 7.0), ('n', 7.0), ('b', 6.0), ('f', 4.0), ('h', 4.0), ('u', 4.0), ('z', 3.0), ('a', 3.0), ('y', 3.0), ('e', 3.0), ('c', 2.0), ('p', 2.0), ('j', 2.0), ('l', 1.0), ('i', 1.0), ('s', 1.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Repeat: Set an array (rank) from all 26 letters to float (rank('A')=rank('B')=...=rank('Z')=0.0)\n",
    "count_min = min(garbled_letters_counter_obj.values())\n",
    "garbled_lower_letter_freq_dict = {k: v/count_min for k, v in garbled_letters_counter_obj.items() if k.lower() == k}\n",
    "count_min = min(garbled_lower_letter_freq_dict.values())\n",
    "garbled_lower_letter_freq_dict = {k: v/count_min for k, v in garbled_lower_letter_freq_dict.items()}\n",
    "garbled_letter_ranked_tuples_list = sorted([(k, v) for k, v in garbled_lower_letter_freq_dict.items()], key=lambda x:x[1], reverse=True)\n",
    "garbled_letter_ranked_tuples_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e67ae7c-6f50-4fe2-bf6f-653c69e43650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qrfcvgr zl vavgvny vzchyfr gung V fubhyq pbagenqvpg jubrire fnvq gung, \"qngr n qhqr\" jba bhg sbe zr\n",
      "reodiae wb iuiainm iwdlmoe atna I otslmr hsuacnriha gtsekec onir atna, \"rnae n rlre\" gsu sla psc we\n",
      "ew csp als usg \"erlr n eanr\" ,anta rino cekestg ahirncaush rmlsto I anta eomldwi mniaiui bw eaidoer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "replacement_dict = {'v': 'i', 'V': 'I', 'z': 'w'}\n",
    "gts_list = [garbled_tuple for garbled_tuple in garbled_letter_ranked_tuples_list if garbled_tuple[0] not in replacement_dict.keys()]\n",
    "lts_list = [letter_tuple for letter_tuple in letter_ranked_tuples_list if letter_tuple[0] not in replacement_dict.values()]\n",
    "for garbled_tuple, letter_tuple in zip(gts_list, lts_list):\n",
    "    replacement_dict[garbled_tuple[0]] = letter_tuple[0]\n",
    "print(encoded_text)\n",
    "decoded_text = ''.join(map(lambda x: replacement_dict.get(x, x), encoded_text))\n",
    "print(decoded_text)\n",
    "print(decoded_text[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d561177-5955-4b15-8327-5dd3984f614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'to', 'in', 'on', 'is', 'he', 'as', 'it', 'by', 'at', 'an', 'be', 'or', 'we', 'up', 'if', 'no', 'do', 'us', 'so', 'my', 'go', 'me', 'al', 'de', 'eu', 'un', 'tv', 'ii', 'ca', 'am', 'la', 'wo', 'el', 'ap', 'km', 'co', 're', 'bc', 'uk', 'ex', 'st', 'li', 'le', 'gm', 'ad', 'mm', 'ah', 'en', 'oh', 'pm', 'cd', 'fc', 'ma', 'hu', 'ed', 'ee', 'wu', 'da', 'uh', 'sa', 'di', 'ok', 'du', 'fm', 'et', 'pc', 'hk', 'bp', 'ho', 'nt', 'au', 'fa', 'iv', 'nn', 'ag', 'il', 'na', 'mp', 'mr', 'dr', 'ac', 'ld', 'ny', 'kg', 'ni', 'vs', 'yu', 'ep', 'se', 'dj', 'bt', 'cm', 'dc', 'ai', 'lu', 'pa', 'hp', 'ha', 'mi', 'ss', 'vi', 'su', 'ab', 'es', 'ge', 'ki', 'ba', 'ft', 'xi', 'gp', 'id', 'lo', 'jo', 'yi', 'ji', 'fu', 'xu', 'td', 'lp', 'ur', 'fe', 'te', 'ih', 'mo', 'hi', 'bo', 'mg', 'nl', 'sr', 'nz', 'os', 'ga', 'ms', 'eh', 'ce', 'hd', 'pg', 'er', 'jp', 'va', 'sc', 'oz', 'md', 'oo', 'ty', 'fi', 'cc', 'ul', 'si', 'rn', 'aa', 'ip', 'tb', 'sm', 'op', 'ng', 'pt', 'po', 'ya', 'th', 'sk', 'uc', 'ka', 'im', 'ec', 'gb', 'ye', 'wb', 'wa', 'ix', 'vw', 'mw', 'cn', 'ku', 'cb', 'lb', 'sp', 'fr', 'ta', 'yo', 'rs', 'pp', 'ay', 'ot', 'sq', 'kl', 'pr', 'ko', 'lg', 'gt', 'hy', 'ne', 'ra', 'jr', 'mc', 'sv', 'wp', 'pf', 'ct', 'ut', 'qi', 'nc', 'ri', 'cr', 'tu', 'db', 'ch', 'fk', 'ml', 'kw', 'qb', 'ti', 'sy', 'nv', 'mk', 'pi', 'mu', 'ju', 'rb', 'rp', 'cy', 'ky', 'ak', 'lt', 'af', 'az', 'hr', 'um', 'ds', 'bi', 'cw', 'cs', 'nm', 'nw', 'bb', 'xp', 'ps', 'tt', 'dp', 'sf', 'ar', 'mv', 'bu', 'xv', 'tf', 'dl', 'ea', 'mb', 'ph', 'wi', 'ig', 'fl', 'ou', 'nu', 'iq', 'bn', 'sw', 'mt', 'ja', 'cq', 'ax', 'fx', 'vu', 'gc', 'ik', 'tc', 'fy', 'sg', 'tx', 'em', 'jc', 'cf', 'rd', 'dh', 'nk', 'kc', 'sh', 'sl', 'wr', 'gs', 'xm', 'jl', 'gi', 'hq', 'vp', 'og', 'cu', 'rr', 'av', 'sd', 'gu', 'jg', 'rw', 'rv', 'sb', 'tr', 'ry', 'ly', 'je', 'bk', 'ek', 'bs', 'ke', 'pv', 'ao', 'nj', 'om', 'js', 'xx', 'vc', 'bg', 'dy', 'sn', 'ol', 'cp', 'nr', 'lm', 'ib', 'dm', 'ff', 'gf', 'hc', 'fg', 'ua', 'zu', 'kb', 'vj', 'ae', 'uf', 'np', 'ci', 'ic', 'ns', 'ox', 'pe', 'uv', 'ir', 'jd', 'rc', 'ts', 'jk', 'br', 'bm', 'ie', 'mn', 'eb', 'hz', 'hm', 'nh', 'rf', 'lf', 'ev', 'ht', 'll', 'dk', 'pd', 'hs', 'ud', 'pq', 'ls', 'xl', 'fo', 'fn', 'ze', 'uw', 'rt', 'gr', 'dg', 'zy', 'zi', 'jw', 'pu', 'kv', 'bf', 'aj', 'ob', 'aw', 'mf', 'ro', 'ru', 'tk', 'kt', 'qu', 'fw', 'vx', 'rk', 'ui', 'gq', 'eg', 'hh', 'kk', 'sj', 'nd', 'rm', 'rl', 'lc', 'vo', 've', 'qc', 'tl', 'ia', 'tm', 'vt', 'jh', 'fd', 'bh', 'io', 'dd', 'fb', 'tn', 'kr', 'cl', 'ej', 'dt', 'cj', 'cg', 'pl', 'jj', 'oy', 'ks', 'hb', 'wc', 'fs', 'nb', 'py', 'rx', 'jb', 'gj', 'oc', 'bv', 'tp', 'bj', 'pj', 'kh', 'hg', 'vg', 'pb', 'gl', 'tg', 'yd', 'vr', 'qf', 'jf', 'cv', 'lw', 'za', 'lk', 'nf', 'jt', 'oi', 'gk', 'mx', 'gd', 'dw', 'iu', 'bw', 'ub', 'bl', 'ef', 'hf', 'ln', 'tj', 'lv', 'rj', 'ck', 'wd', 'kd', 'ei', 'jm', 'gh', 'od', 'dx', 'kj', 'gw', 'lx', 'eq', 'hl', 'vy', 'ez', 'zx', 'vn', 'bd', 'oe', 'jv', 'ue', 'mj', 'ws', 'fp', 'bq', 'wy', 'pk', 'zz', 'oa', 'lj', 'rh', 'xs', 'zk', 'df', 'dq', 'yk', 'iz', 'eo', 'dv', 'xe', 'yr', 'kp', 'ww', 'wv', 'qt', 'gx', 'gy', 'xo', 'bz', 'lh', 'kf', 'ow', 'xy', 'ew', 'xd', 'fh', 'qs', 'kn', 'tz', 'wh', 'qa', 'hv', 'wf', 'dn', 'aq', 'lr', 'rg', 'zo', 'oj', 'gn', 'mh', 'ij', 'qr', 'vf', 'yb', 'vb', 'vm', 'pw', 'px', 'zf', 'pn', 'wm', 'tw', 'gg', 'xt', 'sz', 'wk', 'wt', 'qe', 'cx', 'xb', 'xf', 'yn', 'vz', 'hx', 'wg', 'cz', 'vv', 'xa', 'jn', 'sx', 'ys', 'xc', 'xr', 'ey', 'ov', 'fv', 'lz', 'hj', 'nx', 'fj', 'mz', 'kx', 'hw', 'bx', 'dz', 'hn', 'uz', 'ym', 'ql', 'jy', 'xj', 'qq', 'vl', 'ug', 'kz', 'vk', 'zn', 'qm', 'xk', 'uy', 'vd', 'zh', 'yg', 'xn', 'uu', 'wl', 'uo', 'zd', 'zg', 'wn', 'tq', 'zb', 'gv', 'zt', 'kq', 'iw', 'yc', 'wz', 'pz', 'zr', 'qp', 'qd', 'ux', 'zs', 'zc', 'jz', 'zm', 'mq', 'vh', 'rz', 'yp', 'yy', 'fz', 'yt', 'wx', 'uq', 'uj', 'nq', 'zp', 'wj', 'jx', 'xg', 'yz', 'qv', 'qo', 'iy', 'qn', 'qx', 'xz', 'yl', 'lq', 'xh', 'yx', 'yw', 'vq', 'gz', 'zl', 'yj', 'xq', 'zw', 'zj', 'yf', 'xw', 'yh', 'oq', 'yv', 'qj', 'rq', 'fq', 'qh', 'qk', 'qw']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "glove_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2039d-acca-4551-9b82-09f90078cf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare your garbled distribution with the normal one and regarble your text according to that.\n",
    "\n",
    "# Repeat: Set an array (rank) from all 26 letters to float (rank('A')=rank('B')=...=rank('Z')=0.0)\n",
    "\n",
    "# Check the words in the produced text against words in the dictionary.\n",
    "# If a word is in the dictionary, raise the rank of that word's letters (something like: add a standard value, say 1.0).\n",
    "# In other words calculate Score (a function of total rank and number of words in dictionary).\n",
    "\n",
    "# Save text into High score table (if score high enough).\n",
    "\n",
    "# If all words are in the dictionary or if the total rank is high enough or if the loop was done more than 10000 times, End.\n",
    "\n",
    "# If not, choose randomly two letters and interchange them.\n",
    "# But with a deviated distribution, letters with high rank should have less chances of being interchanged.\n",
    "\n",
    "# Repeat.\n",
    "\n",
    "# End: Print High score texts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
